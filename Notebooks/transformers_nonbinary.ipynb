{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002ffd23-8e36-46c0-aff0-811b7ba476f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /Users/users/mahesh/.local/lib/python3.11/site-packages (1.0.15)\n",
      "Requirement already satisfied: torch in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from timm) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from timm) (0.19.0)\n",
      "Requirement already satisfied: pyyaml in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /Users/users/mahesh/.local/lib/python3.11/site-packages (from timm) (0.29.3)\n",
      "Requirement already satisfied: safetensors in /Users/users/mahesh/.local/lib/python3.11/site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (23.1)\n",
      "Requirement already satisfied: requests in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.6.20)\n",
      "Requirement already satisfied: numpy in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torchvision->timm) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a6af88b-a93e-427c-8b07-39596e43986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c24fdeb3-1ee6-4245-92aa-3acbf7f68aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f80c9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Notebooks', '/Software/users/modules/9/software/anaconda3/2024.02/lib/python311.zip', '/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11', '/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/lib-dynload', '', '/Users/users/mahesh/.local/lib/python3.11/site-packages', '/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages', '/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts']\n",
      "True good\n",
      "1 devices\n",
      "(24953159680, 25339101184)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "sys.path.append('/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts')\n",
    "print(sys.path)\n",
    "import DataCore_Akhil as DC\n",
    "import AkhilFunctions as AF\n",
    "import auxiliary_functions as af\n",
    "import plotting\n",
    "\n",
    "import torch\n",
    "print(f\"{torch.cuda.is_available()} good\")\n",
    "print(f\"{torch.cuda.device_count()} devices\")\n",
    "print(torch.cuda.mem_get_info())\n",
    "\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, TensorDataset, Subset, ConcatDataset\n",
    "from astropy.io import fits\n",
    "import torchvision\n",
    "import timm\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf251c37-2474-4ff4-8fb6-47bffaf24fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05086d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/net/virgo01/data/users/mahesh/DeepLearning/data/\"\n",
    "labeldir = \"/net/virgo01/data/users/spirov/Deep/catalog_tng100_jwst_all_50sns.fits\"\n",
    "labels = fits.open(labeldir)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eccb067d-82a6-45d2-8cb2-ebe5c6f368cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = labels.data['is_major_merger'] == 0\n",
    "mask2 = labels.data['is_pre_merger'] == 0\n",
    "mask3 = labels.data['is_ongoing_merger'] == 1\n",
    "mask4 = labels.data['is_post_merger'] == 0\n",
    "#print(len(labels.data[mask1 & mask2 & mask3 & mask4]))\n",
    "#print(len(labels.data[mask1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cc214-1ed0-493c-83ef-b19743419ad0",
   "metadata": {},
   "source": [
    "major: 2383\n",
    "\n",
    "pre only: 1236\\\n",
    "ongoing only: 511\\\n",
    "post only: 605\\\n",
    "pre and post: 31\\\n",
    "sum: 2383\n",
    "31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aa12b-2af4-4afe-baa7-36321b1956bc",
   "metadata": {},
   "source": [
    "# Multi-target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d909dd8-532a-4e42-a59b-4af0884897ea",
   "metadata": {},
   "source": [
    "## DeiT III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccad7fe-4ddf-4277-9e06-2471bb2424d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "deit3_multi = timm.create_model(\"deit3_base_patch16_224\", pretrained = True)\n",
    "num_classes = 3\n",
    "deit3_multi.head = nn.Linear(deit3_multi.head.in_features, num_classes)\n",
    "\n",
    "# Freeze all parameters first\n",
    "for param in deit3_multi.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the classification head\n",
    "if hasattr(deit3_multi, \"head\"):\n",
    "    for param in deit3_multi.head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Unfreeze the last num_unfreeze transformer blocks\n",
    "num_unfreeze = 4\n",
    "if hasattr(deit3_multi, \"blocks\"):\n",
    "    for block in deit3_multi.blocks[-num_unfreeze:]:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "deit3_multi = deit3_multi.to(device)\n",
    "\n",
    "config = timm.data.resolve_model_data_config(deit3_multi)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n",
    "    transforms.Lambda(lambda img: img.squeeze(0) if img.shape[0] == 1 else img),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(config[\"input_size\"][1:]),  # Resize to model's expected input size\n",
    "    #transforms.RandomResizedCrop(256, scale=(0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.Grayscale(num_output_channels=3),   # Convert grayscale to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda t: AF.aggressive_arcsinh(t)),\n",
    "    transforms.Normalize(mean=config[\"mean\"], std=config[\"std\"])  # Use model-specific normalization\n",
    "])\n",
    "\n",
    "multidata = DC.nonbinary_ClassificationDataset(datadir, labels, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72966b8f-5440-48f2-bc89-5cb8b8142ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation/test transform without augmentations\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n",
    "    transforms.Lambda(lambda img: img.squeeze(0) if img.shape[0] == 1 else img),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(config[\"input_size\"][1:]),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda t: aggressive_arcsinh(t)),\n",
    "    transforms.Normalize(mean=config[\"mean\"], std=config[\"std\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888225f8-ea68-488f-b060-3716875da671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deit3_multi.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b495390-7e5f-48fb-88b3-b8860031ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267\n",
      "1147\n",
      "31\n",
      "56053\n",
      "\n",
      "1236\n",
      "1116\n",
      "31\n",
      "56053\n"
     ]
    }
   ],
   "source": [
    "strat_labels = np.empty(len(labels.data), dtype = int)\n",
    "mask_pre = labels.data['is_pre_merger'] == 1\n",
    "mask_post = labels.data['is_post_merger'] == 1\n",
    "mask_ongoing = labels.data['is_ongoing_merger'] == 1\n",
    "mask_non = labels.data['is_major_merger'] == 0\n",
    "\n",
    "strat_labels[mask_pre] = 1\n",
    "strat_labels[mask_post | mask_ongoing] = 2\n",
    "strat_labels[mask_non] = 0\n",
    "strat_labels[mask_pre & mask_post] = 3\n",
    "\n",
    "print(len(strat_labels[mask_pre]))\n",
    "print(len(strat_labels[mask_post | mask_ongoing]))\n",
    "print(len(strat_labels[mask_pre & mask_post]))\n",
    "print(len(strat_labels[mask_non]))\n",
    "print('')\n",
    "print(np.sum((strat_labels == 1)))\n",
    "print(np.sum((strat_labels == 2)))\n",
    "print(np.sum((strat_labels == 3)))\n",
    "print(np.sum((strat_labels == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02405624-f8bd-4a14-9c12-01be597d4832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58436\n",
      "58436\n",
      "58405\n",
      "58405\n"
     ]
    }
   ],
   "source": [
    "# Assume strat_labels is a NumPy array with your labels.\n",
    "all_indices = np.arange(len(multidata))\n",
    "print(len(all_indices))\n",
    "print(len(strat_labels))\n",
    "\n",
    "# Remove labels with 3 (i.e. samples to be ignored)\n",
    "noneMask = (strat_labels != 3)\n",
    "filtered_all_indices = all_indices[noneMask]\n",
    "filtered_strat_labels = strat_labels[noneMask]\n",
    "\n",
    "print(len(filtered_all_indices))\n",
    "print(len(filtered_strat_labels))\n",
    "\n",
    "# Create relative indices for the filtered dataset\n",
    "relative_indices = np.arange(len(filtered_strat_labels))\n",
    "\n",
    "# First split: 80% train, 20% temporary\n",
    "train_idx_rel, temp_idx_rel = train_test_split(\n",
    "    relative_indices, test_size=0.20, stratify=filtered_strat_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Map the relative indices back to the original indices\n",
    "train_idx = filtered_all_indices[train_idx_rel]\n",
    "temp_idx = filtered_all_indices[temp_idx_rel]\n",
    "\n",
    "train_strat_labels = filtered_strat_labels[train_idx_rel]\n",
    "first_train_strat_labels = train_strat_labels\n",
    "\n",
    "desample_factor = 0.6\n",
    "augmentation_factor = 3\n",
    "\n",
    "# For the temporary set, get its stratification labels (relative indices)\n",
    "temp_strat_labels = filtered_strat_labels[temp_idx_rel]\n",
    "\n",
    "# Second split: split temp indices equally into validation and test sets\n",
    "val_idx_rel, test_idx_rel = train_test_split(\n",
    "    temp_idx_rel, test_size=0.5, stratify=filtered_strat_labels[temp_idx_rel], random_state=42\n",
    ")\n",
    "\n",
    "# Map these relative indices back to the original indices\n",
    "val_idx = filtered_all_indices[val_idx_rel]\n",
    "test_idx = filtered_all_indices[test_idx_rel]\n",
    "\n",
    "# Create the Subset datasets (using your custom SubsetWithTransform for validation and test)\n",
    "multi_train_dataset = Subset(multidata, train_idx)\n",
    "multi_val_dataset = AF.SubsetWithTransform(multidata, val_idx, transform=val_test_transform)\n",
    "multi_test_dataset = AF.SubsetWithTransform(multidata, test_idx, transform=val_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6566eaf1-d602-44a0-a031-8b89db419f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.arange(len(multi_train_dataset))\n",
    "\n",
    "# Create a boolean mask for the majority class (0,0)\n",
    "mask_majority = train_strat_labels == 0\n",
    "majority_indices = all_indices[mask_majority]\n",
    "\n",
    "# Downsample the (0,0) samples to 80% of their original count\n",
    "new_majority_indices = np.random.choice(majority_indices, \n",
    "                                          size=int(desample_factor * len(majority_indices)), \n",
    "                                          replace=False)\n",
    "\n",
    "# For the minority classes, keep all indices\n",
    "minority_indices = all_indices[~mask_majority]\n",
    "\n",
    "# Combine the indices and optionally shuffle them\n",
    "new_indices = np.concatenate([new_majority_indices, minority_indices])\n",
    "np.random.shuffle(new_indices)\n",
    "\n",
    "train_strat_labels = train_strat_labels[new_indices]\n",
    "\n",
    "# Create a new Subset dataset with the new indices\n",
    "multi_train_dataset = Subset(multi_train_dataset, new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c4424d-d8ba-4023-abb3-39b8a3c36efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28787"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8ce6af-b388-42dd-9f8e-b3ec770f3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for minority samples (i.e., not [0,0])\n",
    "minority_mask = ~(train_strat_labels == 0)\n",
    "minority_indices = np.where(minority_mask)[0].tolist()\n",
    "\n",
    "# Create a subset for the minority samples\n",
    "minority_dataset = Subset(multi_train_dataset, minority_indices)\n",
    "\n",
    "# Concatenate the original dataset with the minority subset (doubling the minority samples)\n",
    "for i in range(augmentation_factor-1):\n",
    "    multi_train_dataset = ConcatDataset([multi_train_dataset, minority_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adca9482-37ad-4564-9136-cb5027566ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32551"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06597c22-7097-43c1-9ed0-8ac5b635541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(0.81 * len(multidata))\n",
    "# val_size = int(0.09*len(multidata))\n",
    "# test_size = len(multidata) - train_size - val_size\n",
    "# multi_train_dataset, multi_val_dataset, multi_test_dataset = random_split(multidata, [train_size, val_size, test_size])\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "prefetch_factor = 2\n",
    "persistent_workers = True\n",
    "multi_train_loader = DataLoader(multi_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                          pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "multi_val_loader = DataLoader(multi_val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                        pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "multi_test_loader = DataLoader(multi_test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                         pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "\n",
    "# x,y = next(iter(multi_train_loader))\n",
    "# print(\"x batch shape:\", x.shape)  # Should be [batch_size, 3, 224, 224]\n",
    "# print(\"y batch shape:\", y.shape)  # Should be [batch_size, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d0a550-7fdd-47ab-90ba-ef0a5f0d973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/AkhilFunctions.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a3bc4a-801a-478b-bbd7-f6a7f5ab6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([1,4,4], dtype=torch.float32, device = device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight)  #\n",
    "#optimizer = optim.Adam(deit3_multi.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "optimizer = optim.AdamW(deit3_multi.parameters(),\n",
    "                        lr=1e-4,            # learning rate, adjust as needed\n",
    "                        betas=(0.9, 0.999), # momentum parameters\n",
    "                        eps=1e-8,           # term added to improve numerical stability\n",
    "                        weight_decay=0.01)  # decoupled weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f4762-6c14-4ff2-ae88-18858b236c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "num_training_steps = epochs*len(multi_train_loader)  # total steps (e.g., epochs * batches_per_epoch)\n",
    "num_warmup_steps = int(0.075*num_training_steps)     # warmup for the first 100 steps\n",
    "scheduler = AF.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9c13e6c-ba9b-488d-9d58-1acab88647c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1131, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/queue.py\", line 179, in get\n",
      "    raise Empty\n",
      "_queue.Empty\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1818835/358516871.py\", line 12, in <module>\n",
      "    train_loss = AF.training_epoch(deit3_multi, multi_train_loader, optimizer, criterion, device, unsqueezeY = False)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/AkhilFunctions.py\", line 41, in training_epoch\n",
      "    for X, Y in tqdm(train_loader, desc=\"Training\", leave=False):\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/tqdm/std.py\", line 1178, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 437, in __iter__\n",
      "    self._iterator._reset(self)\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1110, in _reset\n",
      "    return_idx, return_data = self._get_data()\n",
      "                              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1283, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1144, in _try_get_data\n",
      "    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e\n",
      "RuntimeError: DataLoader worker (pid(s) 1849409, 1849500, 1849571, 1849636) exited unexpectedly\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "deit3_multi_train_losses = []\n",
    "deit3_multi_val_losses = []\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    train_loss = AF.training_epoch(deit3_multi, multi_train_loader, optimizer, criterion, device, unsqueezeY = False)\n",
    "    val_loss, val_acc, all_preds, all_labels = AF.nonbinary_multilabel_evaluate(deit3_multi, multi_val_loader, criterion, device, desc = 'validation')\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | Val Acc: {val_acc:.3f}\")\n",
    "\n",
    "    deit3_multi_train_losses.append(train_loss)\n",
    "    deit3_multi_val_losses.append(val_loss)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{epochs} took {epoch_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "deit3_multi_epoch_loss, deit3_multi_epoch_acc, deit3_multi_all_preds, deit3_multi_all_labels = AF.nonbinary_multilabel_evaluate(deit3_multi, multi_test_loader,\n",
    "                                                                                                                  criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6c661-1976-4649-b8a7-5a539e8ea796",
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch+1 == epochs:\n",
    "    ep = epochs\n",
    "else:\n",
    "    ep = epoch\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(np.arange(ep), deit3_multi_train_losses, label=\"Training\")\n",
    "ax.plot(np.arange(ep), deit3_multi_val_losses, label=\"Validation\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1ea87e8-5c05-4fa3-ab96-4acefca802a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/DataCore_Akhil.py\", line 178, in __getitem__\n    given = self.transform(torch.tensor(img))\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_container.py\", line 51, in forward\n    outputs = transform(*inputs)\n              ^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py\", line 50, in forward\n    flat_outputs = [\n                   ^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py\", line 51, in <listcomp>\n    self._transform(inpt, params) if needs_transform else inpt\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_misc.py\", line 39, in _transform\n    return self.lambd(inpt)\n           ^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_3297230/3557687747.py\", line 27, in <lambda>\n    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/auxiliary_functions.py\", line 30, in aggressive_arcsinh_scaling\n    image_scaled[image_scaled < median_val] = median_val\n    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: can't assign a numpy.float32 to a torch.FloatTensor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deit3_multi_epoch_loss, deit3_multi_epoch_acc, deit3_multi_all_preds, deit3_multi_all_labels \u001b[38;5;241m=\u001b[39m AF\u001b[38;5;241m.\u001b[39mnonbinary_multilabel_evaluate(deit3_multi, multi_test_loader,\n\u001b[1;32m      2\u001b[0m                                                                                                                   criterion, device)\n",
      "File \u001b[0;32m/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/AkhilFunctions.py:108\u001b[0m, in \u001b[0;36mnonbinary_multilabel_evaluate\u001b[0;34m(model, loader, criterion, device, desc)\u001b[0m\n\u001b[1;32m    105\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(loader, desc\u001b[38;5;241m=\u001b[39mdesc, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    109\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    110\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Ensure labels are integer class indices\u001b[39;00m\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/DataCore_Akhil.py\", line 178, in __getitem__\n    given = self.transform(torch.tensor(img))\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_container.py\", line 51, in forward\n    outputs = transform(*inputs)\n              ^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py\", line 50, in forward\n    flat_outputs = [\n                   ^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py\", line 51, in <listcomp>\n    self._transform(inpt, params) if needs_transform else inpt\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_misc.py\", line 39, in _transform\n    return self.lambd(inpt)\n           ^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_3297230/3557687747.py\", line 27, in <lambda>\n    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/auxiliary_functions.py\", line 30, in aggressive_arcsinh_scaling\n    image_scaled[image_scaled < median_val] = median_val\n    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: can't assign a numpy.float32 to a torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "deit3_multi_epoch_loss, deit3_multi_epoch_acc, deit3_multi_all_preds, deit3_multi_all_labels = AF.nonbinary_multilabel_evaluate(deit3_multi, multi_test_loader,\n",
    "                                                                                                                  criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b154e-e4f5-48eb-b7a2-b774ba304240",
   "metadata": {},
   "outputs": [],
   "source": [
    "af.plot_confusion_matrix(deit3_multi_all_labels, deit3_multi_all_preds, classes=None, normalize=True, title=None, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785052d6-379f-49de-bafd-f8cbfaa14581",
   "metadata": {},
   "source": [
    "## Swin V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3929e4d6-322c-481a-9e5e-747f0de685a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m swin_multi \u001b[38;5;241m=\u001b[39m timm\u001b[38;5;241m.\u001b[39mcreate_model(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mswinv2_base_window16_256\u001b[39m\u001b[38;5;124m\"\u001b[39m, pretrained \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#swin_multi.head = nn.Linear(swin_multi.head.in_features, num_classes)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/timm/models/_factory.py:126\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, cache_dir, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m create_fn \u001b[38;5;241m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_layer_config(scriptable\u001b[38;5;241m=\u001b[39mscriptable, exportable\u001b[38;5;241m=\u001b[39mexportable, no_jit\u001b[38;5;241m=\u001b[39mno_jit):\n\u001b[0;32m--> 126\u001b[0m     model \u001b[38;5;241m=\u001b[39m create_fn(\n\u001b[1;32m    127\u001b[0m         pretrained\u001b[38;5;241m=\u001b[39mpretrained,\n\u001b[1;32m    128\u001b[0m         pretrained_cfg\u001b[38;5;241m=\u001b[39mpretrained_cfg,\n\u001b[1;32m    129\u001b[0m         pretrained_cfg_overlay\u001b[38;5;241m=\u001b[39mpretrained_cfg_overlay,\n\u001b[1;32m    130\u001b[0m         cache_dir\u001b[38;5;241m=\u001b[39mcache_dir,\n\u001b[1;32m    131\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    132\u001b[0m     )\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    135\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/timm/models/swin_transformer_v2.py:1006\u001b[0m, in \u001b[0;36mswinv2_base_window16_256\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1005\u001b[0m model_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(window_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, depths\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m18\u001b[39m, \u001b[38;5;241m2\u001b[39m), num_heads\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m32\u001b[39m))\n\u001b[0;32m-> 1006\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _create_swin_transformer_v2(\n\u001b[1;32m   1007\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswinv2_base_window16_256\u001b[39m\u001b[38;5;124m'\u001b[39m, pretrained\u001b[38;5;241m=\u001b[39mpretrained, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mdict\u001b[39m(model_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/timm/models/swin_transformer_v2.py:888\u001b[0m, in \u001b[0;36m_create_swin_transformer_v2\u001b[0;34m(variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m    885\u001b[0m default_out_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(i \u001b[38;5;28;01mfor\u001b[39;00m i, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdepths\u001b[39m\u001b[38;5;124m'\u001b[39m, (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))))\n\u001b[1;32m    886\u001b[0m out_indices \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_indices\u001b[39m\u001b[38;5;124m'\u001b[39m, default_out_indices)\n\u001b[0;32m--> 888\u001b[0m model \u001b[38;5;241m=\u001b[39m build_model_with_cfg(\n\u001b[1;32m    889\u001b[0m     SwinTransformerV2, variant, pretrained,\n\u001b[1;32m    890\u001b[0m     pretrained_filter_fn\u001b[38;5;241m=\u001b[39mcheckpoint_filter_fn,\n\u001b[1;32m    891\u001b[0m     feature_cfg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(flatten_sequential\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, out_indices\u001b[38;5;241m=\u001b[39mout_indices),\n\u001b[1;32m    892\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    893\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/timm/models/_builder.py:424\u001b[0m, in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, cache_dir, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;66;03m# Instantiate the model\u001b[39;00m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_cfg \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 424\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_cls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m     model \u001b[38;5;241m=\u001b[39m model_cls(cfg\u001b[38;5;241m=\u001b[39mmodel_cfg, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/timm/models/swin_transformer_v2.py:699\u001b[0m, in \u001b[0;36mSwinTransformerV2.__init__\u001b[0;34m(self, img_size, patch_size, in_chans, num_classes, global_pool, embed_dim, depths, num_heads, window_size, always_partition, strict_img_size, mlp_ratio, qkv_bias, drop_rate, proj_drop_rate, attn_drop_rate, drop_path_rate, act_layer, norm_layer, pretrained_window_sizes, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;241m=\u001b[39m norm_layer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features)\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead \u001b[38;5;241m=\u001b[39m ClassifierHead(\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_features,\n\u001b[1;32m    693\u001b[0m     num_classes,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    696\u001b[0m     input_fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_fmt,\n\u001b[1;32m    697\u001b[0m )\n\u001b[0;32m--> 699\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_weights)\n\u001b[1;32m    700\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m bly \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[1;32m    701\u001b[0m     bly\u001b[38;5;241m.\u001b[39m_init_respostnorm()\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py:895\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m \n\u001b[1;32m    893\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 895\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m    896\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py:895\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m \n\u001b[1;32m    893\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 895\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m    896\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "    \u001b[0;31m[... skipping similar frames: Module.apply at line 895 (3 times)]\u001b[0m\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py:895\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    859\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Apply ``fn`` recursively to every submodule (as returned by ``.children()``) as well as self.\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \n\u001b[1;32m    861\u001b[0m \u001b[38;5;124;03mTypical use includes initializing the parameters of a model\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    892\u001b[0m \n\u001b[1;32m    893\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 895\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[1;32m    896\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py:896\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m    895\u001b[0m     module\u001b[38;5;241m.\u001b[39mapply(fn)\n\u001b[0;32m--> 896\u001b[0m fn(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/timm/models/swin_transformer_v2.py:705\u001b[0m, in \u001b[0;36mSwinTransformerV2._init_weights\u001b[0;34m(self, m)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, m):\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, nn\u001b[38;5;241m.\u001b[39mLinear):\n\u001b[0;32m--> 705\u001b[0m         trunc_normal_(m\u001b[38;5;241m.\u001b[39mweight, std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.02\u001b[39m)\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, nn\u001b[38;5;241m.\u001b[39mLinear) \u001b[38;5;129;01mand\u001b[39;00m m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    707\u001b[0m             nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mconstant_(m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/timm/layers/weight_init.py:67\u001b[0m, in \u001b[0;36mtrunc_normal_\u001b[0;34m(tensor, mean, std, a, b)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Fills the input Tensor with values drawn from a truncated\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03mnormal distribution. The values are effectively drawn from the\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;124;03mnormal distribution :math:`\\mathcal{N}(\\text{mean}, \\text{std}^2)`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;124;03m    >>> nn.init.trunc_normal_(w)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _trunc_normal_(tensor, mean, std, a, b)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/timm/layers/weight_init.py:28\u001b[0m, in \u001b[0;36m_trunc_normal_\u001b[0;34m(tensor, mean, std, a, b)\u001b[0m\n\u001b[1;32m     24\u001b[0m u \u001b[38;5;241m=\u001b[39m norm_cdf((b \u001b[38;5;241m-\u001b[39m mean) \u001b[38;5;241m/\u001b[39m std)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Uniformly fill tensor with values from [l, u], then translate to\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# [2l-1, 2u-1].\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m tensor\u001b[38;5;241m.\u001b[39muniform_(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m l \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m u \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Use inverse cdf transform for normal distribution to get truncated\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# standard normal\u001b[39;00m\n\u001b[1;32m     32\u001b[0m tensor\u001b[38;5;241m.\u001b[39merfinv_()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "swin_multi = timm.create_model(\"swinv2_base_window16_256\", pretrained = True)\n",
    "num_classes = 3\n",
    "#swin_multi.head = nn.Linear(swin_multi.head.in_features, num_classes)\n",
    "swin_multi.reset_classifier(num_classes, global_pool='avg')\n",
    "\n",
    "# Freeze all parameters first\n",
    "for param in swin_multi.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the classification head\n",
    "if hasattr(swin_multi, \"head\"):\n",
    "    for param in swin_multi.head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Unfreeze the last num_unfreeze layers\n",
    "# num_unfreeze = 1\n",
    "# for layers in swin_multi.layers[-num_unfreeze:]:\n",
    "#         for param in layers.parameters():\n",
    "#             param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "swin_multi = swin_multi.to(device)\n",
    "\n",
    "config = timm.data.resolve_model_data_config(swin_multi)\n",
    "\n",
    "noise_std = 0.05\n",
    "add_noise = transforms.Lambda(lambda x: x + torch.randn_like(x) * noise_std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n",
    "    transforms.Lambda(lambda img: img.squeeze(0) if img.shape[0] == 1 else img),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(config[\"input_size\"][1:]),  # Resize to model's expected input size\n",
    "    #transforms.RandomResizedCrop(256, scale=(0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    #transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.Grayscale(num_output_channels=3),   # Convert grayscale to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    #add_noise,\n",
    "    #transforms.Lambda(lambda t: AF.aggressive_arcsinh(t)),\n",
    "    transforms.Normalize(mean=config[\"mean\"], std=config[\"std\"])  # Use model-specific normalization\n",
    "])\n",
    "\n",
    "swin_multidata = DC.nonbinary_ClassificationDataset(datadir, labels, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470e4c2e-4e9d-47fa-b928-b1f7245ab8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation/test transform without augmentations\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n",
    "    transforms.Lambda(lambda img: img.squeeze(0) if img.shape[0] == 1 else img),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(config[\"input_size\"][1:]),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda t: aggressive_arcsinh(t)),\n",
    "    transforms.Normalize(mean=config[\"mean\"], std=config[\"std\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f61bf23-c793-4122-a6de-7b57f237106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_labels = np.empty(len(labels.data), dtype = int)\n",
    "mask_pre = labels.data['is_pre_merger'] == 1\n",
    "mask_post = labels.data['is_post_merger'] == 1\n",
    "mask_ongoing = labels.data['is_ongoing_merger'] == 1\n",
    "mask_non = labels.data['is_major_merger'] == 0\n",
    "\n",
    "strat_labels[mask_pre] = 1\n",
    "strat_labels[mask_post | mask_ongoing] = 2\n",
    "strat_labels[mask_non] = 0\n",
    "strat_labels[mask_pre & mask_post] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b868c-038c-49d0-b150-35ade9d1d7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume strat_labels is a NumPy array with your labels.\n",
    "all_indices = np.arange(len(swin_multidata))\n",
    "print(len(all_indices))\n",
    "print(len(strat_labels))\n",
    "\n",
    "# Remove labels with 3 (i.e. samples to be ignored)\n",
    "noneMask = (strat_labels != 3)\n",
    "filtered_all_indices = all_indices[noneMask]\n",
    "filtered_strat_labels = strat_labels[noneMask]\n",
    "\n",
    "print(len(filtered_all_indices))\n",
    "print(len(filtered_strat_labels))\n",
    "\n",
    "# Create relative indices for the filtered dataset\n",
    "relative_indices = np.arange(len(filtered_strat_labels))\n",
    "\n",
    "# First split: 80% train, 20% temporary\n",
    "train_idx_rel, temp_idx_rel = train_test_split(\n",
    "    relative_indices, test_size=0.20, stratify=filtered_strat_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Map the relative indices back to the original indices\n",
    "train_idx = filtered_all_indices[train_idx_rel]\n",
    "temp_idx = filtered_all_indices[temp_idx_rel]\n",
    "\n",
    "train_strat_labels = filtered_strat_labels[train_idx_rel]\n",
    "first_train_strat_labels = train_strat_labels\n",
    "\n",
    "desample_factor = 0.9\n",
    "augmentation_factor = 3\n",
    "\n",
    "# For the temporary set, get its stratification labels (relative indices)\n",
    "temp_strat_labels = filtered_strat_labels[temp_idx_rel]\n",
    "\n",
    "# Second split: split temp indices equally into validation and test sets\n",
    "val_idx_rel, test_idx_rel = train_test_split(\n",
    "    temp_idx_rel, test_size=0.5, stratify=filtered_strat_labels[temp_idx_rel], random_state=42\n",
    ")\n",
    "\n",
    "# Map these relative indices back to the original indices\n",
    "val_idx = filtered_all_indices[val_idx_rel]\n",
    "test_idx = filtered_all_indices[test_idx_rel]\n",
    "\n",
    "# Create the Subset datasets (using your custom SubsetWithTransform for validation and test)\n",
    "swin_multi_train_dataset = Subset(swin_multidata, train_idx)\n",
    "swin_multi_val_dataset = AF.SubsetWithTransform(swin_multidata, val_idx, transform=val_test_transform)\n",
    "swin_multi_test_dataset = AF.SubsetWithTransform(swin_multidata, test_idx, transform=val_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef3fa8f3-cce5-4e0e-8a77-65caf978ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.arange(len(swin_multi_train_dataset))\n",
    "\n",
    "# Create a boolean mask for the majority class (0,0)\n",
    "mask_majority = train_strat_labels == 0\n",
    "majority_indices = all_indices[mask_majority]\n",
    "\n",
    "# Downsample the (0,0) samples to 80% of their original count\n",
    "new_majority_indices = np.random.choice(majority_indices, \n",
    "                                          size=int(desample_factor * len(majority_indices)), \n",
    "                                          replace=False)\n",
    "\n",
    "# For the minority classes, keep all indices\n",
    "minority_indices = all_indices[~mask_majority]\n",
    "\n",
    "# Combine the indices and optionally shuffle them\n",
    "new_indices = np.concatenate([new_majority_indices, minority_indices])\n",
    "np.random.shuffle(new_indices)\n",
    "\n",
    "train_strat_labels = train_strat_labels[new_indices]\n",
    "\n",
    "# Create a new Subset dataset with the new indices\n",
    "swin_multi_train_dataset = Subset(swin_multi_train_dataset, new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4152a074-6147-4d17-bcd6-066f9ae584d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(swin_multi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e979586-86fe-40ea-9e25-ee53123cd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for minority samples (i.e., not [0,0])\n",
    "minority_mask = ~(train_strat_labels == 0)\n",
    "minority_indices = np.where(minority_mask)[0].tolist()\n",
    "\n",
    "# Create a subset for the minority samples\n",
    "minority_dataset = Subset(swin_multi_train_dataset, minority_indices)\n",
    "\n",
    "# Concatenate the original dataset with the minority subset (doubling the minority samples)\n",
    "for i in range(augmentation_factor-1):\n",
    "    swin_multi_train_dataset = ConcatDataset([swin_multi_train_dataset, minority_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd752a9-035f-481d-a0a9-19d3c3eb87ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(swin_multi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6387c56-3539-44c6-b819-29b1449feba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(0.81 * len(swin_multidata))\n",
    "# val_size = int(0.09*len(swin_multidata))\n",
    "# test_size = len(swin_multidata) - train_size - val_size\n",
    "# swin_multi_train_dataset, swin_multi_val_dataset, swin_multi_test_dataset = random_split(swin_multidata, [train_size, val_size, test_size])\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "prefetch_factor = 2\n",
    "persistent_workers = True\n",
    "swin_multi_train_loader = DataLoader(swin_multi_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                          pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "swin_multi_val_loader = DataLoader(swin_multi_val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                        pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "swin_multi_test_loader = DataLoader(swin_multi_test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                         pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "\n",
    "# x,y = next(iter(swin_multi_train_loader))\n",
    "# print(\"x batch shape:\", x.shape)  # Should be [batch_size, 3, 224, 224]\n",
    "# print(\"y batch shape:\", y.shape)  # Should be [batch_size, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e281f09-ce80-4697-9245-c364b92a79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([0.5,10,10], dtype=torch.float32, device = device)\n",
    "N = len(swin_multi_train_dataset)\n",
    "n1 = np.sum((train_strat_labels == 1))*1.52#*augmentation_factor\n",
    "n2 = np.sum((train_strat_labels == 2))*1.57#*augmentation_factor\n",
    "n0 = np.sum((train_strat_labels == 0))*0.85#*desample_factor\n",
    "C=3\n",
    "w0 = N / (C * n0)\n",
    "w1 = N / (C * n1)\n",
    "w2 = N / (C * n2)\n",
    "\n",
    "weight = torch.tensor([0.7,w1,w2], dtype=torch.float32, device = device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "#optimizer = optim.Adam(swin_multi.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "optimizer = optim.AdamW(swin_multi.parameters(),\n",
    "                        lr=2e-5,            # learning rate, adjust as needed\n",
    "                        betas=(0.9, 0.999), # momentum parameters\n",
    "                        eps=1e-8,           # term added to improve numerical stability\n",
    "                        weight_decay=0.01)  # decoupled weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ea4106-575f-4c1f-aa72-fadec380516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(n0,n1,n2)\n",
    "print(w0,w1,w2)\n",
    "print(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b175c-d28f-469b-9753-ba08b1c63c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "num_training_steps = epochs*len(swin_multi_train_loader)  # total steps (e.g., epochs * batches_per_epoch)\n",
    "num_warmup_steps = int(0.05*num_training_steps)\n",
    "#scheduler = AF.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77d1e7-8d16-4be4-b478-6f48b49b5d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_multi_train_losses = []\n",
    "swin_multi_val_losses = []\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_bal_acc = 0.49\n",
    "best_combined_acc = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    train_loss = AF.training_epoch(swin_multi, swin_multi_train_loader, optimizer, criterion, device, scheduler = None, unsqueezeY = False)\n",
    "    val_loss, val_acc, all_preds, all_labels, bal_acc = AF.nonbinary_multilabel_evaluate(swin_multi, swin_multi_val_loader, criterion, device, desc = 'validation')\n",
    "\n",
    "    # Step the scheduler\n",
    "    #scheduler.step()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | Val Acc: {val_acc:.3f} | Balanced Acc: {bal_acc:.3f}\")\n",
    "\n",
    "    swin_multi_train_losses.append(train_loss)\n",
    "    swin_multi_val_losses.append(val_loss)\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{epochs} took {epoch_time:.2f} seconds\")\n",
    "\n",
    "    # if val_loss < best_val_loss:\n",
    "    #     best_val_loss = val_loss\n",
    "    #     torch.save(swin_multi.state_dict(), \"swin_nonbinary_best_model.pth\")\n",
    "\n",
    "    if (epoch+1)%5 == 0:\n",
    "        af.plot_confusion_matrix(all_labels, all_preds, classes=None, normalize=True, title=None, cmap=plt.cm.Blues)\n",
    "        plt.show()\n",
    "    \n",
    "    if bal_acc > best_bal_acc:\n",
    "        best_bal_acc = bal_acc\n",
    "        torch.save(swin_multi.state_dict(), \"swin_nonbinary_best_model_bal_acc.pth\")\n",
    "\n",
    "    if bal_acc + val_acc > best_combined_acc:\n",
    "        best_combined_acc = bal_acc + val_acc\n",
    "        torch.save(swin_multi.state_dict(), \"swin_nonbinary_best_model_combined_acc.pth\")\n",
    "\n",
    "swin_multi_epoch_loss, swin_multi_epoch_acc, swin_multi_all_preds, swin_multi_all_labels, swin_multi_bal_acc = AF.nonbinary_multilabel_evaluate(swin_multi, swin_multi_test_loader,\n",
    "                                                                                                                  criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d7e6c-5e06-4b96-a1e6-940dc2799d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch+1 == epochs:\n",
    "    ep = epochs\n",
    "else:\n",
    "    ep = epoch\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(np.arange(ep), swin_multi_train_losses, label=\"Training\")\n",
    "ax.plot(np.arange(ep), swin_multi_val_losses, label=\"Validation\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "205dbcdb-8d9d-4c22-b612-4471e1502c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "swin_multi_epoch_loss, swin_multi_epoch_acc, swin_multi_all_preds, swin_multi_all_labels, swin_multi_bal_acc = AF.nonbinary_multilabel_evaluate(swin_multi, swin_multi_test_loader,\n",
    "                                                                                                                  criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "21fcbb2c-3a7a-4e8a-92e3-87aa085aca5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40232836843006337\n",
      "0.4781746951283048\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(swin_multi_epoch_acc)\n",
    "print(swin_multi_bal_acc)\n",
    "af.plot_confusion_matrix(swin_multi_all_labels, swin_multi_all_preds, classes=None, normalize=True, title=None, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "020bcf34-1ec3-4614-bec4-bd1e4d79da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_strat_labels(dataset):\n",
    "#     labels = []\n",
    "#     for i in range(len(dataset)):\n",
    "#         _, label = dataset[i]\n",
    "#         label = tuple(label.cpu().numpy())\n",
    "#         labels.append(label)\n",
    "#     return labels\n",
    "\n",
    "# def print_distribution_ratios(labels, subset_name=\"\"):\n",
    "#     counts = Counter(labels)\n",
    "#     total = sum(counts.values())\n",
    "#     print(f\"{subset_name} distribution ratios:\")\n",
    "#     for label, count in counts.items():\n",
    "#         ratio = count / total\n",
    "#         print(f\"  {label}: {ratio:.3f}\")\n",
    "#     print()\n",
    "\n",
    "# orig_labels = get_strat_labels(multidata)\n",
    "# train_labels = get_strat_labels(swin_multi_train_dataset)\n",
    "# val_labels = get_strat_labels(swin_multi_val_dataset)\n",
    "# test_labels = get_strat_labels(swin_multi_test_dataset)\n",
    "\n",
    "# print_distribution_ratios(orig_labels, \"Original\")\n",
    "# print_distribution_ratios(train_labels, \"Train\")\n",
    "# print_distribution_ratios(val_labels, \"Validation\")\n",
    "# print_distribution_ratios(test_labels, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b026b489-46fc-4833-a6ae-a48e6b216b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10%5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd764a5b-bcd2-425b-97d1-b2634974ea7d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
