{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002ffd23-8e36-46c0-aff0-811b7ba476f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /Users/users/mahesh/.local/lib/python3.11/site-packages (1.0.15)\n",
      "Requirement already satisfied: torch in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from timm) (2.4.0)\n",
      "Requirement already satisfied: torchvision in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from timm) (0.19.0)\n",
      "Requirement already satisfied: pyyaml in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from timm) (6.0.1)\n",
      "Requirement already satisfied: huggingface_hub in /Users/users/mahesh/.local/lib/python3.11/site-packages (from timm) (0.29.3)\n",
      "Requirement already satisfied: safetensors in /Users/users/mahesh/.local/lib/python3.11/site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (23.1)\n",
      "Requirement already satisfied: requests in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from huggingface_hub->timm) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (1.12)\n",
      "Requirement already satisfied: networkx in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (3.1.3)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torch->timm) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->timm) (12.6.20)\n",
      "Requirement already satisfied: numpy in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torchvision->timm) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from torchvision->timm) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from jinja2->torch->timm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from requests->huggingface_hub->timm) (2025.1.31)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --user timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6af88b-a93e-427c-8b07-39596e43986b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip show timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c24fdeb3-1ee6-4245-92aa-3acbf7f68aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f80c9a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Notebooks', '/Software/users/modules/9/software/anaconda3/2024.02/lib/python311.zip', '/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11', '/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/lib-dynload', '', '/Users/users/mahesh/.local/lib/python3.11/site-packages', '/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages', '/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/AkhilFunctions.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True good\n",
      "1 devices\n",
      "(24953159680, 25339101184)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "\n",
    "sys.path.append('/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts')\n",
    "print(sys.path)\n",
    "import DataCore_Akhil as DC\n",
    "import AkhilFunctions as AF\n",
    "import auxiliary_functions as af\n",
    "import plotting\n",
    "\n",
    "import torch\n",
    "print(f\"{torch.cuda.is_available()} good\")\n",
    "print(f\"{torch.cuda.device_count()} devices\")\n",
    "print(torch.cuda.mem_get_info())\n",
    "\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, TensorDataset, Subset, ConcatDataset\n",
    "from astropy.io import fits\n",
    "import torchvision\n",
    "import timm\n",
    "import torchvision.transforms.v2 as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf251c37-2474-4ff4-8fb6-47bffaf24fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.cuda.memory_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05086d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = \"/net/virgo01/data/users/mahesh/DeepLearning/data/\"\n",
    "labeldir = \"/net/virgo01/data/users/spirov/Deep/catalog_tng100_jwst_all_50sns.fits\"\n",
    "labels = fits.open(labeldir)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eccb067d-82a6-45d2-8cb2-ebe5c6f368cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = labels.data['is_major_merger'] == 0\n",
    "mask2 = labels.data['is_pre_merger'] == 0\n",
    "mask3 = labels.data['is_ongoing_merger'] == 1\n",
    "mask4 = labels.data['is_post_merger'] == 0\n",
    "#print(len(labels.data[mask1 & mask2 & mask3 & mask4]))\n",
    "#print(len(labels.data[mask1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18cc214-1ed0-493c-83ef-b19743419ad0",
   "metadata": {},
   "source": [
    "major: 2383\n",
    "\n",
    "pre only: 1236\\\n",
    "ongoing only: 511\\\n",
    "post only: 605\\\n",
    "pre and post: 31\\\n",
    "sum: 2383\n",
    "31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3aa12b-2af4-4afe-baa7-36321b1956bc",
   "metadata": {},
   "source": [
    "# Multi-target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d909dd8-532a-4e42-a59b-4af0884897ea",
   "metadata": {},
   "source": [
    "## DeiT III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ccad7fe-4ddf-4277-9e06-2471bb2424d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "deit3_multi = timm.create_model(\"deit3_base_patch16_224\", pretrained = True)\n",
    "num_classes = 3\n",
    "deit3_multi.head = nn.Linear(deit3_multi.head.in_features, num_classes)\n",
    "\n",
    "# Freeze all parameters first\n",
    "for param in deit3_multi.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the classification head\n",
    "if hasattr(deit3_multi, \"head\"):\n",
    "    for param in deit3_multi.head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Unfreeze the last num_unfreeze transformer blocks\n",
    "num_unfreeze = 4\n",
    "if hasattr(deit3_multi, \"blocks\"):\n",
    "    for block in deit3_multi.blocks[-num_unfreeze:]:\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "deit3_multi = deit3_multi.to(device)\n",
    "\n",
    "config = timm.data.resolve_model_data_config(deit3_multi)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n",
    "    transforms.Lambda(lambda img: img.squeeze(0) if img.shape[0] == 1 else img),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(config[\"input_size\"][1:]),  # Resize to model's expected input size\n",
    "    #transforms.RandomResizedCrop(256, scale=(0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.Grayscale(num_output_channels=3),   # Convert grayscale to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda t: AF.aggressive_arcsinh(t)),\n",
    "    transforms.Normalize(mean=config[\"mean\"], std=config[\"std\"])  # Use model-specific normalization\n",
    "])\n",
    "\n",
    "multidata = DC.nonbinary_ClassificationDataset(datadir, labels, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72966b8f-5440-48f2-bc89-5cb8b8142ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation/test transform without augmentations\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n",
    "    transforms.Lambda(lambda img: img.squeeze(0) if img.shape[0] == 1 else img),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(config[\"input_size\"][1:]),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda t: aggressive_arcsinh(t)),\n",
    "    transforms.Normalize(mean=config[\"mean\"], std=config[\"std\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888225f8-ea68-488f-b060-3716875da671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(deit3_multi.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b495390-7e5f-48fb-88b3-b8860031ceca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267\n",
      "1147\n",
      "31\n",
      "56053\n",
      "\n",
      "1236\n",
      "1116\n",
      "31\n",
      "56053\n"
     ]
    }
   ],
   "source": [
    "strat_labels = np.empty(len(labels.data), dtype = int)\n",
    "mask_pre = labels.data['is_pre_merger'] == 1\n",
    "mask_post = labels.data['is_post_merger'] == 1\n",
    "mask_ongoing = labels.data['is_ongoing_merger'] == 1\n",
    "mask_non = labels.data['is_major_merger'] == 0\n",
    "\n",
    "strat_labels[mask_pre] = 1\n",
    "strat_labels[mask_post | mask_ongoing] = 2\n",
    "strat_labels[mask_non] = 0\n",
    "strat_labels[mask_pre & mask_post] = 3\n",
    "\n",
    "print(len(strat_labels[mask_pre]))\n",
    "print(len(strat_labels[mask_post | mask_ongoing]))\n",
    "print(len(strat_labels[mask_pre & mask_post]))\n",
    "print(len(strat_labels[mask_non]))\n",
    "print('')\n",
    "print(np.sum((strat_labels == 1)))\n",
    "print(np.sum((strat_labels == 2)))\n",
    "print(np.sum((strat_labels == 3)))\n",
    "print(np.sum((strat_labels == 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02405624-f8bd-4a14-9c12-01be597d4832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58436\n",
      "58436\n",
      "58405\n",
      "58405\n"
     ]
    }
   ],
   "source": [
    "# Assume strat_labels is a NumPy array with your labels.\n",
    "all_indices = np.arange(len(multidata))\n",
    "print(len(all_indices))\n",
    "print(len(strat_labels))\n",
    "\n",
    "# Remove labels with 3 (i.e. samples to be ignored)\n",
    "noneMask = (strat_labels != 3)\n",
    "filtered_all_indices = all_indices[noneMask]\n",
    "filtered_strat_labels = strat_labels[noneMask]\n",
    "\n",
    "print(len(filtered_all_indices))\n",
    "print(len(filtered_strat_labels))\n",
    "\n",
    "# Create relative indices for the filtered dataset\n",
    "relative_indices = np.arange(len(filtered_strat_labels))\n",
    "\n",
    "# First split: 80% train, 20% temporary\n",
    "train_idx_rel, temp_idx_rel = train_test_split(\n",
    "    relative_indices, test_size=0.20, stratify=filtered_strat_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Map the relative indices back to the original indices\n",
    "train_idx = filtered_all_indices[train_idx_rel]\n",
    "temp_idx = filtered_all_indices[temp_idx_rel]\n",
    "\n",
    "train_strat_labels = filtered_strat_labels[train_idx_rel]\n",
    "first_train_strat_labels = train_strat_labels\n",
    "\n",
    "desample_factor = 0.6\n",
    "augmentation_factor = 3\n",
    "\n",
    "# For the temporary set, get its stratification labels (relative indices)\n",
    "temp_strat_labels = filtered_strat_labels[temp_idx_rel]\n",
    "\n",
    "# Second split: split temp indices equally into validation and test sets\n",
    "val_idx_rel, test_idx_rel = train_test_split(\n",
    "    temp_idx_rel, test_size=0.5, stratify=filtered_strat_labels[temp_idx_rel], random_state=42\n",
    ")\n",
    "\n",
    "# Map these relative indices back to the original indices\n",
    "val_idx = filtered_all_indices[val_idx_rel]\n",
    "test_idx = filtered_all_indices[test_idx_rel]\n",
    "\n",
    "# Create the Subset datasets (using your custom SubsetWithTransform for validation and test)\n",
    "multi_train_dataset = Subset(multidata, train_idx)\n",
    "multi_val_dataset = AF.SubsetWithTransform(multidata, val_idx, transform=val_test_transform)\n",
    "multi_test_dataset = AF.SubsetWithTransform(multidata, test_idx, transform=val_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6566eaf1-d602-44a0-a031-8b89db419f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.arange(len(multi_train_dataset))\n",
    "\n",
    "# Create a boolean mask for the majority class (0,0)\n",
    "mask_majority = train_strat_labels == 0\n",
    "majority_indices = all_indices[mask_majority]\n",
    "\n",
    "# Downsample the (0,0) samples to 80% of their original count\n",
    "new_majority_indices = np.random.choice(majority_indices, \n",
    "                                          size=int(desample_factor * len(majority_indices)), \n",
    "                                          replace=False)\n",
    "\n",
    "# For the minority classes, keep all indices\n",
    "minority_indices = all_indices[~mask_majority]\n",
    "\n",
    "# Combine the indices and optionally shuffle them\n",
    "new_indices = np.concatenate([new_majority_indices, minority_indices])\n",
    "np.random.shuffle(new_indices)\n",
    "\n",
    "train_strat_labels = train_strat_labels[new_indices]\n",
    "\n",
    "# Create a new Subset dataset with the new indices\n",
    "multi_train_dataset = Subset(multi_train_dataset, new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c4424d-d8ba-4023-abb3-39b8a3c36efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28787"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f8ce6af-b388-42dd-9f8e-b3ec770f3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for minority samples (i.e., not [0,0])\n",
    "minority_mask = ~(train_strat_labels == 0)\n",
    "minority_indices = np.where(minority_mask)[0].tolist()\n",
    "\n",
    "# Create a subset for the minority samples\n",
    "minority_dataset = Subset(multi_train_dataset, minority_indices)\n",
    "\n",
    "# Concatenate the original dataset with the minority subset (doubling the minority samples)\n",
    "for i in range(augmentation_factor-1):\n",
    "    multi_train_dataset = ConcatDataset([multi_train_dataset, minority_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adca9482-37ad-4564-9136-cb5027566ced",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32551"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06597c22-7097-43c1-9ed0-8ac5b635541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(0.81 * len(multidata))\n",
    "# val_size = int(0.09*len(multidata))\n",
    "# test_size = len(multidata) - train_size - val_size\n",
    "# multi_train_dataset, multi_val_dataset, multi_test_dataset = random_split(multidata, [train_size, val_size, test_size])\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "prefetch_factor = 2\n",
    "persistent_workers = True\n",
    "multi_train_loader = DataLoader(multi_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                          pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "multi_val_loader = DataLoader(multi_val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                        pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "multi_test_loader = DataLoader(multi_test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                         pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "\n",
    "# x,y = next(iter(multi_train_loader))\n",
    "# print(\"x batch shape:\", x.shape)  # Should be [batch_size, 3, 224, 224]\n",
    "# print(\"y batch shape:\", y.shape)  # Should be [batch_size, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4d0a550-7fdd-47ab-90ba-ef0a5f0d973c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/AkhilFunctions.py:9: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(multi_train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37a3bc4a-801a-478b-bbd7-f6a7f5ab6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([1,4,4], dtype=torch.float32, device = device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight)  #\n",
    "#optimizer = optim.Adam(deit3_multi.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "optimizer = optim.AdamW(deit3_multi.parameters(),\n",
    "                        lr=1e-4,            # learning rate, adjust as needed\n",
    "                        betas=(0.9, 0.999), # momentum parameters\n",
    "                        eps=1e-8,           # term added to improve numerical stability\n",
    "                        weight_decay=0.01)  # decoupled weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f4762-6c14-4ff2-ae88-18858b236c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "num_training_steps = epochs*len(multi_train_loader)  # total steps (e.g., epochs * batches_per_epoch)\n",
    "num_warmup_steps = int(0.075*num_training_steps)     # warmup for the first 100 steps\n",
    "scheduler = AF.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9c13e6c-ba9b-488d-9d58-1acab88647c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Learning Rate: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1131, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/queue.py\", line 179, in get\n",
      "    raise Empty\n",
      "_queue.Empty\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_1818835/358516871.py\", line 12, in <module>\n",
      "    train_loss = AF.training_epoch(deit3_multi, multi_train_loader, optimizer, criterion, device, unsqueezeY = False)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/AkhilFunctions.py\", line 41, in training_epoch\n",
      "    for X, Y in tqdm(train_loader, desc=\"Training\", leave=False):\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/tqdm/std.py\", line 1178, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 437, in __iter__\n",
      "    self._iterator._reset(self)\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1110, in _reset\n",
      "    return_idx, return_data = self._get_data()\n",
      "                              ^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1283, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1144, in _try_get_data\n",
      "    raise RuntimeError(f'DataLoader worker (pid(s) {pids_str}) exited unexpectedly') from e\n",
      "RuntimeError: DataLoader worker (pid(s) 1849409, 1849500, 1849571, 1849636) exited unexpectedly\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1435, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1326, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1173, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 1088, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 970, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "    ^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/IPython/core/ultratb.py\", line 792, in lines\n",
      "    return self._sd.lines\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/core.py\", line 698, in lines\n",
      "    pieces = self.included_pieces\n",
      "             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/core.py\", line 649, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "                             ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/stack_data/core.py\", line 628, in executing_piece\n",
      "    return only(\n",
      "           ^^^^^\n",
      "  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/executing/executing.py\", line 164, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "deit3_multi_train_losses = []\n",
    "deit3_multi_val_losses = []\n",
    "\n",
    "#scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = epochs)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    train_loss = AF.training_epoch(deit3_multi, multi_train_loader, optimizer, criterion, device, unsqueezeY = False)\n",
    "    val_loss, val_acc, all_preds, all_labels = AF.nonbinary_multilabel_evaluate(deit3_multi, multi_val_loader, criterion, device, desc = 'validation')\n",
    "\n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | Val Acc: {val_acc:.3f}\")\n",
    "\n",
    "    deit3_multi_train_losses.append(train_loss)\n",
    "    deit3_multi_val_losses.append(val_loss)\n",
    "\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{epochs} took {epoch_time:.2f} seconds\")\n",
    "\n",
    "\n",
    "deit3_multi_epoch_loss, deit3_multi_epoch_acc, deit3_multi_all_preds, deit3_multi_all_labels = AF.nonbinary_multilabel_evaluate(deit3_multi, multi_test_loader,\n",
    "                                                                                                                  criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef6c661-1976-4649-b8a7-5a539e8ea796",
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch+1 == epochs:\n",
    "    ep = epochs\n",
    "else:\n",
    "    ep = epoch\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(np.arange(ep), deit3_multi_train_losses, label=\"Training\")\n",
    "ax.plot(np.arange(ep), deit3_multi_val_losses, label=\"Validation\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1ea87e8-5c05-4fa3-ab96-4acefca802a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/DataCore_Akhil.py\", line 178, in __getitem__\n    given = self.transform(torch.tensor(img))\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_container.py\", line 51, in forward\n    outputs = transform(*inputs)\n              ^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py\", line 50, in forward\n    flat_outputs = [\n                   ^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py\", line 51, in <listcomp>\n    self._transform(inpt, params) if needs_transform else inpt\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_misc.py\", line 39, in _transform\n    return self.lambd(inpt)\n           ^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_3297230/3557687747.py\", line 27, in <lambda>\n    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/auxiliary_functions.py\", line 30, in aggressive_arcsinh_scaling\n    image_scaled[image_scaled < median_val] = median_val\n    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: can't assign a numpy.float32 to a torch.FloatTensor\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m deit3_multi_epoch_loss, deit3_multi_epoch_acc, deit3_multi_all_preds, deit3_multi_all_labels \u001b[38;5;241m=\u001b[39m AF\u001b[38;5;241m.\u001b[39mnonbinary_multilabel_evaluate(deit3_multi, multi_test_loader,\n\u001b[1;32m      2\u001b[0m                                                                                                                   criterion, device)\n",
      "File \u001b[0;32m/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/AkhilFunctions.py:108\u001b[0m, in \u001b[0;36mnonbinary_multilabel_evaluate\u001b[0;34m(model, loader, criterion, device, desc)\u001b[0m\n\u001b[1;32m    105\u001b[0m all_labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(loader, desc\u001b[38;5;241m=\u001b[39mdesc, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    109\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    110\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Ensure labels are integer class indices\u001b[39;00m\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     data\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/DataCore_Akhil.py\", line 178, in __getitem__\n    given = self.transform(torch.tensor(img))\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_container.py\", line 51, in forward\n    outputs = transform(*inputs)\n              ^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py\", line 50, in forward\n    flat_outputs = [\n                   ^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_transform.py\", line 51, in <listcomp>\n    self._transform(inpt, params) if needs_transform else inpt\n    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_misc.py\", line 39, in _transform\n    return self.lambd(inpt)\n           ^^^^^^^^^^^^^^^^\n  File \"/tmp/ipykernel_3297230/3557687747.py\", line 27, in <lambda>\n    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/auxiliary_functions.py\", line 30, in aggressive_arcsinh_scaling\n    image_scaled[image_scaled < median_val] = median_val\n    ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^\nTypeError: can't assign a numpy.float32 to a torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "deit3_multi_epoch_loss, deit3_multi_epoch_acc, deit3_multi_all_preds, deit3_multi_all_labels = AF.nonbinary_multilabel_evaluate(deit3_multi, multi_test_loader,\n",
    "                                                                                                                  criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b154e-e4f5-48eb-b7a2-b774ba304240",
   "metadata": {},
   "outputs": [],
   "source": [
    "af.plot_confusion_matrix(deit3_multi_all_labels, deit3_multi_all_preds, classes=None, normalize=True, title=None, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785052d6-379f-49de-bafd-f8cbfaa14581",
   "metadata": {},
   "source": [
    "## Swin V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3929e4d6-322c-481a-9e5e-747f0de685a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Software/users/modules/9/software/anaconda3/2024.02/lib/python3.11/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "swin_multi = timm.create_model(\"swinv2_base_window16_256\", pretrained = True)\n",
    "num_classes = 3\n",
    "#swin_multi.head = nn.Linear(swin_multi.head.in_features, num_classes)\n",
    "swin_multi.reset_classifier(num_classes, global_pool='avg')\n",
    "\n",
    "# Freeze all parameters first\n",
    "for param in swin_multi.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze the classification head\n",
    "if hasattr(swin_multi, \"head\"):\n",
    "    for param in swin_multi.head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Unfreeze the last num_unfreeze layers\n",
    "# num_unfreeze = 1\n",
    "# for layers in swin_multi.layers[-num_unfreeze:]:\n",
    "#         for param in layers.parameters():\n",
    "#             param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "swin_multi = swin_multi.to(device)\n",
    "\n",
    "config = timm.data.resolve_model_data_config(swin_multi)\n",
    "\n",
    "noise_std = 0.01\n",
    "add_noise = transforms.Lambda(lambda x: x + torch.randn_like(x) * noise_std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n",
    "    transforms.Lambda(lambda img: img.squeeze(0) if img.shape[0] == 1 else img),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(config[\"input_size\"][1:]),  # Resize to model's expected input size\n",
    "    #transforms.RandomResizedCrop(256, scale=(0.9, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=(0, 360)),\n",
    "    transforms.Grayscale(num_output_channels=3),   # Convert grayscale to 3 channels\n",
    "    transforms.ToTensor(),\n",
    "    #add_noise,\n",
    "    #transforms.Lambda(lambda t: AF.aggressive_arcsinh(t)),\n",
    "    transforms.Normalize(mean=config[\"mean\"], std=config[\"std\"])  # Use model-specific normalization\n",
    "])\n",
    "\n",
    "swin_multidata = DC.nonbinary_ClassificationDataset(datadir, labels, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "470e4c2e-4e9d-47fa-b928-b1f7245ab8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation/test transform without augmentations\n",
    "val_test_transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: af.aggressive_arcsinh_scaling(img)),\n",
    "    transforms.Lambda(lambda img: img.squeeze(0) if img.shape[0] == 1 else img),\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize(config[\"input_size\"][1:]),\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Lambda(lambda t: aggressive_arcsinh(t)),\n",
    "    transforms.Normalize(mean=config[\"mean\"], std=config[\"std\"])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f61bf23-c793-4122-a6de-7b57f237106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_labels = np.empty(len(labels.data), dtype = int)\n",
    "mask_pre = labels.data['is_pre_merger'] == 1\n",
    "mask_post = labels.data['is_post_merger'] == 1\n",
    "mask_ongoing = labels.data['is_ongoing_merger'] == 1\n",
    "mask_non = labels.data['is_major_merger'] == 0\n",
    "\n",
    "strat_labels[mask_pre] = 1\n",
    "strat_labels[mask_post | mask_ongoing] = 2\n",
    "strat_labels[mask_non] = 0\n",
    "strat_labels[mask_pre & mask_post] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df5b868c-038c-49d0-b150-35ade9d1d7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58436\n",
      "58436\n",
      "58405\n",
      "58405\n"
     ]
    }
   ],
   "source": [
    "# Assume strat_labels is a NumPy array with your labels.\n",
    "all_indices = np.arange(len(swin_multidata))\n",
    "print(len(all_indices))\n",
    "print(len(strat_labels))\n",
    "\n",
    "# Remove labels with 3 (i.e. samples to be ignored)\n",
    "noneMask = (strat_labels != 3)\n",
    "filtered_all_indices = all_indices[noneMask]\n",
    "filtered_strat_labels = strat_labels[noneMask]\n",
    "\n",
    "print(len(filtered_all_indices))\n",
    "print(len(filtered_strat_labels))\n",
    "\n",
    "# Create relative indices for the filtered dataset\n",
    "relative_indices = np.arange(len(filtered_strat_labels))\n",
    "\n",
    "# First split: 80% train, 20% temporary\n",
    "train_idx_rel, temp_idx_rel = train_test_split(\n",
    "    relative_indices, test_size=0.20, stratify=filtered_strat_labels, random_state=42\n",
    ")\n",
    "\n",
    "# Map the relative indices back to the original indices\n",
    "train_idx = filtered_all_indices[train_idx_rel]\n",
    "temp_idx = filtered_all_indices[temp_idx_rel]\n",
    "\n",
    "train_strat_labels = filtered_strat_labels[train_idx_rel]\n",
    "first_train_strat_labels = train_strat_labels\n",
    "\n",
    "desample_factor = 0.8\n",
    "augmentation_factor = 2\n",
    "\n",
    "# For the temporary set, get its stratification labels (relative indices)\n",
    "temp_strat_labels = filtered_strat_labels[temp_idx_rel]\n",
    "\n",
    "# Second split: split temp indices equally into validation and test sets\n",
    "val_idx_rel, test_idx_rel = train_test_split(\n",
    "    temp_idx_rel, test_size=0.5, stratify=filtered_strat_labels[temp_idx_rel], random_state=42\n",
    ")\n",
    "\n",
    "# Map these relative indices back to the original indices\n",
    "val_idx = filtered_all_indices[val_idx_rel]\n",
    "test_idx = filtered_all_indices[test_idx_rel]\n",
    "\n",
    "# Create the Subset datasets (using your custom SubsetWithTransform for validation and test)\n",
    "swin_multi_train_dataset = Subset(swin_multidata, train_idx)\n",
    "swin_multi_val_dataset = AF.SubsetWithTransform(swin_multidata, val_idx, transform=val_test_transform)\n",
    "swin_multi_test_dataset = AF.SubsetWithTransform(swin_multidata, test_idx, transform=val_test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef3fa8f3-cce5-4e0e-8a77-65caf978ad75",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.arange(len(swin_multi_train_dataset))\n",
    "\n",
    "# Create a boolean mask for the majority class (0,0)\n",
    "mask_majority = train_strat_labels == 0\n",
    "majority_indices = all_indices[mask_majority]\n",
    "\n",
    "# Downsample the (0,0) samples to 80% of their original count\n",
    "new_majority_indices = np.random.choice(majority_indices, \n",
    "                                          size=int(desample_factor * len(majority_indices)), \n",
    "                                          replace=False)\n",
    "\n",
    "# For the minority classes, keep all indices\n",
    "minority_indices = all_indices[~mask_majority]\n",
    "\n",
    "# Combine the indices and optionally shuffle them\n",
    "new_indices = np.concatenate([new_majority_indices, minority_indices])\n",
    "np.random.shuffle(new_indices)\n",
    "\n",
    "train_strat_labels = train_strat_labels[new_indices]\n",
    "\n",
    "# Create a new Subset dataset with the new indices\n",
    "swin_multi_train_dataset = Subset(swin_multi_train_dataset, new_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4152a074-6147-4d17-bcd6-066f9ae584d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37755"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(swin_multi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e979586-86fe-40ea-9e25-ee53123cd9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask for minority samples (i.e., not [0,0])\n",
    "minority_mask = ~(train_strat_labels == 0)\n",
    "minority_indices = np.where(minority_mask)[0].tolist()\n",
    "\n",
    "# Create a subset for the minority samples\n",
    "minority_dataset = Subset(swin_multi_train_dataset, minority_indices)\n",
    "\n",
    "# Concatenate the original dataset with the minority subset (doubling the minority samples)\n",
    "for i in range(augmentation_factor-1):\n",
    "    swin_multi_train_dataset = ConcatDataset([swin_multi_train_dataset, minority_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9fd752a9-035f-481d-a0a9-19d3c3eb87ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39637"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(swin_multi_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b6387c56-3539-44c6-b819-29b1449feba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_size = int(0.81 * len(swin_multidata))\n",
    "# val_size = int(0.09*len(swin_multidata))\n",
    "# test_size = len(swin_multidata) - train_size - val_size\n",
    "# swin_multi_train_dataset, swin_multi_val_dataset, swin_multi_test_dataset = random_split(swin_multidata, [train_size, val_size, test_size])\n",
    "\n",
    "batch_size = 256\n",
    "num_workers = 4\n",
    "prefetch_factor = 2\n",
    "persistent_workers = True\n",
    "swin_multi_train_loader = DataLoader(swin_multi_train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers,\n",
    "                          pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "swin_multi_val_loader = DataLoader(swin_multi_val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                        pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "swin_multi_test_loader = DataLoader(swin_multi_test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers,\n",
    "                         pin_memory=True, persistent_workers=persistent_workers, prefetch_factor = prefetch_factor)\n",
    "\n",
    "# x,y = next(iter(swin_multi_train_loader))\n",
    "# print(\"x batch shape:\", x.shape)  # Should be [batch_size, 3, 224, 224]\n",
    "# print(\"y batch shape:\", y.shape)  # Should be [batch_size, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e281f09-ce80-4697-9245-c364b92a79c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = torch.tensor([0.3,5,9], dtype=torch.float32, device = device)\n",
    "criterion = nn.CrossEntropyLoss(weight=weight)\n",
    "#optimizer = optim.Adam(swin_multi.parameters(), lr=0.005, weight_decay=1e-4)\n",
    "optimizer = optim.AdamW(swin_multi.parameters(),\n",
    "                        lr=1e-4,            # learning rate, adjust as needed\n",
    "                        betas=(0.9, 0.999), # momentum parameters\n",
    "                        eps=1e-8,           # term added to improve numerical stability\n",
    "                        weight_decay=0.01)  # decoupled weight decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "118b175c-d28f-469b-9753-ba08b1c63c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "num_training_steps = epochs*len(swin_multi_train_loader)  # total steps (e.g., epochs * batches_per_epoch)\n",
    "num_warmup_steps = int(0.07*num_training_steps)\n",
    "scheduler = AF.get_cosine_schedule_with_warmup(optimizer, num_warmup_steps, num_training_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77d1e7-8d16-4be4-b478-6f48b49b5d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Learning Rate: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|                                                                                 | 0/155 [00:00<?, ?it/s]/net/virgo01/data/users/mahesh/DeepLearning/DLP_galaxy_mergers/Scripts/AkhilFunctions.py:49: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.066616 | Val Loss: 1.091425 | Val Acc: 0.232\n",
      "Epoch 1/20 took 257.79 seconds\n",
      "Epoch 2/20 - Learning Rate: 0.000250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.050028 | Val Loss: 1.125344 | Val Acc: 0.071\n",
      "Epoch 2/20 took 246.50 seconds\n",
      "Epoch 3/20 - Learning Rate: 0.000500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.036686 | Val Loss: 1.035508 | Val Acc: 0.361\n",
      "Epoch 3/20 took 245.04 seconds\n",
      "Epoch 4/20 - Learning Rate: 0.000498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.033204 | Val Loss: 1.093792 | Val Acc: 0.085\n",
      "Epoch 4/20 took 244.57 seconds\n",
      "Epoch 5/20 - Learning Rate: 0.000492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  39%|████████████████████████████▎                                           | 61/155 [01:19<02:13,  1.42s/it]"
     ]
    }
   ],
   "source": [
    "swin_multi_train_losses = []\n",
    "swin_multi_val_losses = []\n",
    "\n",
    "best_val_loss = np.inf\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "    train_loss = AF.training_epoch(swin_multi, swin_multi_train_loader, optimizer, criterion, device, scheduler = scheduler, unsqueezeY = False)\n",
    "    val_loss, val_acc, all_preds, all_labels = AF.nonbinary_multilabel_evaluate(swin_multi, swin_multi_val_loader, criterion, device, desc = 'validation')\n",
    "\n",
    "    # Step the scheduler\n",
    "    #scheduler.step()\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.6f} | Val Loss: {val_loss:.6f} | Val Acc: {val_acc:.3f}\")\n",
    "\n",
    "    swin_multi_train_losses.append(train_loss)\n",
    "    swin_multi_val_losses.append(val_loss)\n",
    "    \n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{epochs} took {epoch_time:.2f} seconds\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(swin_multi.state_dict(), \"swin_nonbinary_best_model.pth\")\n",
    "\n",
    "swin_multi_epoch_loss, swin_multi_epoch_acc, swin_multi_all_preds, swin_multi_all_labels = AF.nonbinary_multilabel_evaluate(swin_multi, swin_multi_test_loader,\n",
    "                                                                                                                  criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d7e6c-5e06-4b96-a1e6-940dc2799d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if epoch+1 == epochs:\n",
    "    ep = epochs\n",
    "else:\n",
    "    ep = epoch\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.plot(np.arange(ep), swin_multi_train_losses, label=\"Training\")\n",
    "ax.plot(np.arange(ep), swin_multi_val_losses, label=\"Validation\")\n",
    "ax.legend()\n",
    "ax.set_xlabel(\"Epoch\")\n",
    "ax.set_ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "205dbcdb-8d9d-4c22-b612-4471e1502c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                        \r"
     ]
    }
   ],
   "source": [
    "swin_multi_epoch_loss, swin_multi_epoch_acc, swin_multi_all_preds, swin_multi_all_labels = AF.nonbinary_multilabel_evaluate(swin_multi, swin_multi_test_loader,\n",
    "                                                                                                                  criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21fcbb2c-3a7a-4e8a-92e3-87aa085aca5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "af.plot_confusion_matrix(swin_multi_all_labels, swin_multi_all_preds, classes=None, normalize=True, title=None, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "020bcf34-1ec3-4614-bec4-bd1e4d79da9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_strat_labels(dataset):\n",
    "#     labels = []\n",
    "#     for i in range(len(dataset)):\n",
    "#         _, label = dataset[i]\n",
    "#         label = tuple(label.cpu().numpy())\n",
    "#         labels.append(label)\n",
    "#     return labels\n",
    "\n",
    "# def print_distribution_ratios(labels, subset_name=\"\"):\n",
    "#     counts = Counter(labels)\n",
    "#     total = sum(counts.values())\n",
    "#     print(f\"{subset_name} distribution ratios:\")\n",
    "#     for label, count in counts.items():\n",
    "#         ratio = count / total\n",
    "#         print(f\"  {label}: {ratio:.3f}\")\n",
    "#     print()\n",
    "\n",
    "# orig_labels = get_strat_labels(multidata)\n",
    "# train_labels = get_strat_labels(swin_multi_train_dataset)\n",
    "# val_labels = get_strat_labels(swin_multi_val_dataset)\n",
    "# test_labels = get_strat_labels(swin_multi_test_dataset)\n",
    "\n",
    "# print_distribution_ratios(orig_labels, \"Original\")\n",
    "# print_distribution_ratios(train_labels, \"Train\")\n",
    "# print_distribution_ratios(val_labels, \"Validation\")\n",
    "# print_distribution_ratios(test_labels, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026b489-46fc-4833-a6ae-a48e6b216b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
